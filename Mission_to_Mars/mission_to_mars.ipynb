{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up dependencies\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from splinter import Browser\n",
    "import pandas as pd\n",
    "import os\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Current google-chrome version is 89.0.4389\n",
      "[WDM] - Get LATEST driver version for 89.0.4389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Get LATEST driver version for 89.0.4389\n",
      "[WDM] - Trying to download new driver from https://chromedriver.storage.googleapis.com/89.0.4389.23/chromedriver_win32.zip\n",
      "[WDM] - Driver has been saved in cache [C:\\Users\\mthor\\.wdm\\drivers\\chromedriver\\win32\\89.0.4389.23]\n"
     ]
    }
   ],
   "source": [
    "# Setup Chrome Driver for use with Splinter\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NASA Mars News\n",
    "This section:\n",
    "1. uses Splinter to navigate to the NASA Mars Latest News site\n",
    "2. uses BeautifulSoup to scrape the latest article title and teaser text  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "url = 'https://mars.nasa.gov/news/'\n",
    "browser.visit(url)\n",
    "\n",
    "# HTML object\n",
    "html = browser.html\n",
    "\n",
    "# Create BeautifulSoup object; parse with 'html.parser'\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the title, teaser and date from the first list_text class div element on the page\n",
    "article = soup.find('div', class_='list_text')\n",
    "news_title = article.find('div', class_='content_title').text\n",
    "news_teaser = article.find('div', class_='article_teaser_body').text\n",
    "article_date = article.find('div', class_='list_date').text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JPL Mars Space Images - Featured Image\n",
    "This section:\n",
    "1. Uses Splinter to navigate to the JPL Mars Space Images site to find the image URL to the full size image for the latest Featured Mars Image\n",
    "2. Uses BeautifulSoup to parse the html and save the url of this image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://d2pn8kiwq2w21t.cloudfront.net/images/jpegPIA23810.width-1024.jpg\n"
     ]
    }
   ],
   "source": [
    "# Visit the JPL Mars Space Images page\n",
    "url = 'https://www.jpl.nasa.gov/images?search=&category=Mars'\n",
    "browser.visit(url)\n",
    "\n",
    "# Parse the HTML on this page with Beautiful Soup\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "\n",
    "# Find the link to the first displayed Image on the page and navigate to it\n",
    "image_page = soup.find('div', class_='SearchResultCard').a['href']\n",
    "full_image_page = f\"https://www.jpl.nasa.gov{image_page}\"\n",
    "browser.visit(full_image_page)\n",
    "\n",
    "# Parse the image page with Beautiful Soup and find the url of the full size image\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "featured_image_url = soup.find(\"img\", class_=\"BaseImage\").attrs[\"src\"] \n",
    "print(featured_image_url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Facts\n",
    "This section:\n",
    "1. Uses Pandas to parse the html table on the Mars space facts page and saves the Mars facts in a dataframe\n",
    "2. Saves that as an HTML table string\n",
    "2. It also writes it out to an html file for backup purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "url = 'https://space-facts.com/mars/'\n",
    "tables = pd.read_html(url)\n",
    "mars_df = tables[0]\n",
    "mars_df.columns = ['Fact','Detail']\n",
    "mars_df\n",
    "mars_facts_table = mars_df.to_html(justify='left',index=False)\n",
    "mars_df.to_html('mars_facts_tbl.html',justify='left',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Hemispheres\n",
    "This section:\n",
    "1. Uses Splinter to navigate to the Astrogeology Mars Hemispheres pages\n",
    "2. Uses BeautifulSoup to parse the html and retrieve the title and url for each of the 4 hemisphere images.\n",
    "    - **NOTE: this step can be a little slow to run. Make sure it has completed before proceeding to the next cell.**\n",
    "3. Saves this to a Python dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visit the  USGS Astrogeology site and get titles of and links to Hemisphere image pages\n",
    "url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "browser.visit(url)\n",
    "\n",
    "# Parse the HTML on this page with Beautiful Soup\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "\n",
    "# Retrieve the parent divs for all items\n",
    "items = soup.find_all('div', class_='item')\n",
    "\n",
    "link_list = []\n",
    "title_list = []\n",
    "# loop over results to get Hemisphere image info\n",
    "for item in items:\n",
    "    # scrape the image title and link \n",
    "    link = item.find('a', class_='itemLink').attrs[\"href\"] \n",
    "    title = item.find('h3').text\n",
    "    link_list.append(link)\n",
    "    title_list.append(title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Iterate through the list of hemisphere image links and navigate to each individual page to scrape the image url\n",
    "image_list = []\n",
    "for item in link_list:\n",
    "   \n",
    "    #Navigate to new page\n",
    "    article_page = f\"https://astrogeology.usgs.gov{item}\"\n",
    "    browser.visit(article_page)\n",
    "    \n",
    "    # HTML object\n",
    "    html = browser.html\n",
    "    # Parse HTML with Beautiful Soup\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "    # Retrieve elements in the downloads div and get the url to the full image\n",
    "    downloads = soup.find(\"div\", class_=\"downloads\")\n",
    "    image_url = downloads.find('a').attrs[\"href\"]\n",
    "    image_list.append(image_url)\n",
    "      \n",
    " # Create a list of hemisphere dictionaries\n",
    "Cerberus = {'title':title_list[0], 'img_url':image_list[0]}\n",
    "Schiaparelli = {'title':title_list[1], 'img_url':image_list[1]}\n",
    "Syrtis = {'title':title_list[2], 'img_url':image_list[2]}\n",
    "Valles = {'title':title_list[3], 'img_url':image_list[3]}\n",
    "hemisphere_image_urls = [Cerberus, Schiaparelli, Syrtis, Valles]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Hemispheres\n",
    "This section builds a Python dictionary containing all of the scraped Mars data which will be inserted into a MongoDB database by my Flask application (next step)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary of scraped Mars data contains : {'news_title': 'NASA Ingenuity Mars Helicopter Prepares for First Flight', 'news teaser': 'Now uncocooned from its protective carbon-fiber shield, the helicopter is being readied for its next steps.  ', 'featured_image_url': 'https://d2pn8kiwq2w21t.cloudfront.net/images/jpegPIA23810.width-1024.jpg', 'mars_facts_table': '<table border=\"1\" class=\"dataframe\">\\n  <thead>\\n    <tr style=\"text-align: left;\">\\n      <th>Fact</th>\\n      <th>Detail</th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <td>Equatorial Diameter:</td>\\n      <td>6,792 km</td>\\n    </tr>\\n    <tr>\\n      <td>Polar Diameter:</td>\\n      <td>6,752 km</td>\\n    </tr>\\n    <tr>\\n      <td>Mass:</td>\\n      <td>6.39 × 10^23 kg (0.11 Earths)</td>\\n    </tr>\\n    <tr>\\n      <td>Moons:</td>\\n      <td>2 (Phobos &amp; Deimos)</td>\\n    </tr>\\n    <tr>\\n      <td>Orbit Distance:</td>\\n      <td>227,943,824 km (1.38 AU)</td>\\n    </tr>\\n    <tr>\\n      <td>Orbit Period:</td>\\n      <td>687 days (1.9 years)</td>\\n    </tr>\\n    <tr>\\n      <td>Surface Temperature:</td>\\n      <td>-87 to -5 °C</td>\\n    </tr>\\n    <tr>\\n      <td>First Record:</td>\\n      <td>2nd millennium BC</td>\\n    </tr>\\n    <tr>\\n      <td>Recorded By:</td>\\n      <td>Egyptian astronomers</td>\\n    </tr>\\n  </tbody>\\n</table>', 'hemisphere_image_urls': [{'title': 'Cerberus Hemisphere Enhanced', 'img_url': 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif/full.jpg'}, {'title': 'Schiaparelli Hemisphere Enhanced', 'img_url': 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/schiaparelli_enhanced.tif/full.jpg'}, {'title': 'Syrtis Major Hemisphere Enhanced', 'img_url': 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/syrtis_major_enhanced.tif/full.jpg'}, {'title': 'Valles Marineris Hemisphere Enhanced', 'img_url': 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/valles_marineris_enhanced.tif/full.jpg'}]}\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary containing all of my scraped Mars website data\n",
    "Mars_dict = {\n",
    "       'news_title': news_title,\n",
    "       'news teaser': news_teaser,\n",
    "       'featured_image_url': featured_image_url,\n",
    "       'mars_facts_table': str(mars_facts_table),\n",
    "       'hemisphere_image_urls': hemisphere_image_urls\n",
    "    }\n",
    "print (\"Dictionary of scraped Mars data contains : \" +  str(Mars_dict)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
